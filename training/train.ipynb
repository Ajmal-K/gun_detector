{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import json\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.builders import dataset_builder\n",
    "from object_detection.builders import graph_rewriter_builder\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.legacy import trainer\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"\"\n",
    "num_clones = 1\n",
    "clone_on_cpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.contrib.framework.deprecated(None, 'Use object_detection/model_main.py.')\n",
    "def main(_):\n",
    "    assert train_dir, 'train_dir is misssing'\n",
    "    if pipeline_config_path:\n",
    "        configs = config_util.get_config_from_pipeline_file(pipeline_config_path)\n",
    "    else:\n",
    "        None\n",
    "    \n",
    "    model_config = configs['model']\n",
    "    train_config = configs['train_config']\n",
    "    input_config = configs['train_input_config']\n",
    "    \n",
    "    model_fn = functools.partial(model_builder.build,\n",
    "                                model_config=model_config,\n",
    "                                is_training=True)\n",
    "    \n",
    "    def get_next(config):\n",
    "        return dataset_builder.make_initializable_iterator(\n",
    "            dataset_bulder.build(config)).get_next()\n",
    "    \n",
    "    create_input_dict_fn = functools.partial(get_next, input_config)\n",
    "    \n",
    "    env = json.loads(os.environ.get('TF_CONFIG', '{}'))\n",
    "    cluster_data = env.get('cluster', None)\n",
    "    cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None\n",
    "    task_data = env.get('task', None) or {'type': 'master', 'index': 0}\n",
    "    task_info = type('TaskSpec', (object,), task_data)\n",
    "    \n",
    "    # Parameters for a single worker.\n",
    "    ps_tasks = 0\n",
    "    worker_replicas = 1\n",
    "    worker_job_name = 'lonely_worker'\n",
    "    task = 0\n",
    "    is_chief = True\n",
    "    master = ''\n",
    "    \n",
    "    if cluster_data and 'worker' in cluster_data:\n",
    "        # Number of total worker replicas include \"worker\"s and the \"master\".\n",
    "        worker_replicas = len(cluster_data['worker']) + 1\n",
    "    if cluster_data and 'ps' in cluster_data:\n",
    "        ps_tasks = len(cluster_data['ps'])\n",
    "        \n",
    "    if worker_replicas > 1 and ps_tasks < 1:\n",
    "        raise ValueError('At least 1 ps task is needed for distributed training.')\n",
    "\n",
    "    if worker_replicas >= 1 and ps_tasks > 0:\n",
    "        # Set up distributed training.\n",
    "        server = tf.train.Server(tf.train.ClusterSpec(cluster), protocol='grpc',\n",
    "                             job_name=task_info.type,\n",
    "                             task_index=task_info.index)\n",
    "        if task_info.type == 'ps':\n",
    "            server.join()\n",
    "            return\n",
    "        \n",
    "        worker_job_name = '%s/task:%d' % (task_info.type, task_info.index)\n",
    "        task = task_info.index\n",
    "        is_chief = (task_info.type == 'master')\n",
    "        master = server.target\n",
    "        \n",
    "    graph_rewriter_fn = None\n",
    "    \n",
    "    if 'graph_rewriter_config' in configs:\n",
    "        graph_rewriter_fn = graph_rewriter_builder.build(\n",
    "            configs['graph_rewriter_config'], is_training=True)\n",
    "        \n",
    "    trainer.train(create_input_dict_fn,\n",
    "                 model_fn,\n",
    "                 train_config,\n",
    "                 master,\n",
    "                 task,\n",
    "                 num_clones,\n",
    "                 worker_replicas,\n",
    "                 clone_on_cpu,\n",
    "                 ps_tasks,\n",
    "                 worker_job_name,\n",
    "                 is_chief,\n",
    "                 train_dir,\n",
    "                 graph_hook_fn=graph_rewriter_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
